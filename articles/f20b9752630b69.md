---
title: "論文要約: Kaggle コンペ \"Freesound Audio Tagging 2019\" のベースラインモデル"
emoji: "📢"
type: "idea"
topics:
  - "kaggle"
  - "cnn"
  - "音声"
  - "論文要約"
  - "機械学習"
published: true
published_at: "2022-03-03 17:53"
---

# 論文

[Audio tagging with noisy labels and minimal supervision](https://arxiv.org/abs/1906.02975)

# 概要

Kaggle コンペ "Freesound Audio Tagging 2019"[^1] にて、ホストが用意したベースラインモデル[^2]について説明した論文。

# コンペの特徴

1. AudioSetと同様の音声マルチタギングのタスク
2. ラベルが不正確だがサンプル数が多いデータセット(noisy train)とラベルが正確だがサンプル数が少ないデータセット(curated train)の2つが与えられている。それぞれデータソースも異なる。また、評価用ラベルはcrated trainと同じデータソースから作成。
3. コンペティションのメトリクスにlωlrap("lol wrap"と発音)という予測のランクに基づいた指標が採用されている
4. カーネルコンペだが、ノートブックの制限時間が1時間と現在よりもかなり短い

# ベースラインモデルの特徴

1. ノートブックの制限時間に収まるように、MobileNet v1をベースにしたパラメータ数の小さい予測モデルを採用
1. ラベルノイズに対応するために、dropoutとlabel smoothing[^3]を採用
1. 2種類のデータソースのドメインシフトに対応するため、最初noisy trainで表現を学習した後で、curated trainでファインチューン
1. Augmentationは利用せず
1. 外部データを使った事前学習は利用せず

# モデルのパフォーマンス

private LB=0.546。参考として、1st placeのモデル[^4]がprivate LB=0.75980。

[^1]: https://www.kaggle.com/c/freesound-audio-tagging-2019/overview
[^2]: https://github.com/DCASE-REPO/dcase2019_task2_baseline
[^3]: [Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/abs/1512.00567)
[^4]: https://github.com/lRomul/argus-freesound
