---
title: "論文要約: PSLA: 音声CNNモデルのmodel-agnosticな改善手法"
emoji: "😊"
type: "tech"
topics:
  - "cnn"
  - "音声"
  - "論文要約"
published: true
published_at: "2022-03-02 22:48"
---

# 論文

[Improving Audio Tagging with Pretraining, Sampling, Labeling, and Aggregation](https://arxiv.org/abs/2102.01243)

# 概要

音声タギングにおいて、モデルの改善でなく、さまざまな学習方法の改善を適用してパフォーマンスがどう変わるかを詳細に調査した研究。

実はやっていることはPANNs[^1]とほとんど同じだが、実験方法がより詳細に記述されている。

AudioSetデータセットのラベル誤りについて指摘していることは特筆すべき。例えば、"Speech"という親クラスのタグが付加されているにもかかわらず、"Male Speech", "Female Speech", "Child Speech"などの下位クラスのタグが付加されていないデータが大部分を占めるなど。

また、訓練用ラベルだけでなく、評価用ラベルにも同様のラベル誤りが存在する可能性を指摘している。本論文ではPseudoラベルによってモデルの再学習を実施しているが、AudioSetのデータではパフォーマンスが変わらず、より正確なラベルのESC-50, FDS50Kでは改善が見られた。

なお、本論文で採用しているpseudo labelは保守的で、親クラスと下位クラス間のラベル欠落のみに限定している。論文でも指摘しているように、AudioSetのラベル作成プロセスからして、FPは検出できるがFNは検出が難しい。したがって、これ以外にも多くのmissing labelが存在する可能性がある。

# その他特筆すべき点

* AudioSetでフルスクラッチ学習したモデルよりもimagenetで事前学習したモデルの方がパフォーマンスが高かった（十分大きなサンプル数でも同様）
* weight averagingとensembleによりSOTAを達成(mAP=0.474)

# 所感

* PANNs同様、class imbalanceに対してbalanced samplingで対処している。-> Focal Lossなどその他の手法で対処している論文はないか？
* SOTAといっても寄与のほとんどはweight averagingとensemble
* AudioSetのラベルの誤りをPseudo Labelで訂正したデータセットを公開している
* AudioSetの評価用ラベルの誤りについての指摘は興味深い。他の提案手法においてもpseudoラベルで再学習したモデルを使えば、転移学習時にパフォーマンスgainが得られるかもしれない

----

[^1]: [PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition](https://arxiv.org/abs/1912.10211)