---
title: "論文要約: Patchout - 音声タスクにおけるTransformerの効率的な学習手法"
emoji: "⛳"
type: "idea"
topics:
  - "音声"
  - "transformer"
  - "論文要約"
published: true
published_at: "2022-03-03 00:30"
---

# 論文

[Efficient Training of Audio Transformers with Patchout](https://arxiv.org/abs/2110.05069v2)

# 概要

既存のTransformerの学習はCNNと比べて計算リソースを食うことが問題だったが、本論文ではPatchoutという手法を使って市販のGPUを使って現実的な時間で学習を可能にした。

# 提案手法の特徴

1. AST[^3]同様、imagenetでモデルを事前学習(DeiT-B-384ベース)したモデルを使用
2. Positional Embeddingを時間方向と周波数方向で独立して行う
3. Transformerに入力する前のPatchをDropする(Patchout)ことで計算量を削減
4. PatchOutには正則化の効果もある
5. AugmentationではMixup, SpecAugmentに加えて時間方向のRolling, 波形に対してランダムにゲイン(+-7db)を適用

# Patchout

Transformerの計算には入力パッチサイズの2乗の計算量を消費する。したがって、パッチ数を欠落させることは学習速度を早めることにつながる。本論文ではパッチ数を約50%に削減することで学習速度を約4倍にした。

なお、Patchoutとして以下の2種類の方策を試した。

1. Unstructured PatchOut: ランダムに欠落させる
2. Structured PatchOut: 特定の時間、周波数について全てのパッチを欠落させる（SpecAugment[^1]の類推）

パフォーマンスはStructured PatchOutの方が若干良い(mAP +0.5%)。

# パフォーマンス

計算機リソースの効率化が主眼の研究だが、同時にSOTAも達成している(mAP=**0.496**)。しかも、ASTと異なり、シングルモデルでもPANNs[^2](mAP=**0.442**)に比べて大幅に改善している(mAP=**0.471**)。学習時間も比較的短く、市販のGPUカード(Nvidia RTX 2080ti)を使って50時間の学習でSOTAを達成した。

また、3つの転移学習でSOTAを達成した。うち1つはわずか5分の学習時間で実現した。

# 所感

ローエンドの学習環境では本手法は重宝する。

[^1]: [SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition](https://arxiv.org/abs/1904.08779)
[^2]: [PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition](https://arxiv.org/abs/1912.10211)
[^3]: [AST: Audio Spectrogram Transformer](https://arxiv.org/abs/2104.01778v3)