---
title: "論文要約: Tacotron2 - TacotronとWaveNetを組み合わせた音声合成モデル"
emoji: "🐙"
type: "idea"
topics:
  - "音声合成"
  - "論文要約"
  - "rnn"
published: true
published_at: "2022-08-03 11:45"
---

# 論文

[Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions](https://arxiv.org/abs/1712.05884)

# 概要

RNNを用いたsequence-to-sequenceモデルによってテキストからMelスペクトグラムを生成し、改良したWaveNetを使って音声波形を合成するモデルを提案する。
提案モデルはmean opinion score(MOS)という評価指標で4.53を記録し、専門家の録音音声のスコア4.58に匹敵するスコアを記録した。

# 既存研究との違い

本研究は既存研究の「良いとこどり」をしたアーキテクチャを提案する。

WaveNet[^1]は時間領域の波形を生成する生成モデルで、現実の人間のスピーチに匹敵する性能を持つが、入力として言語学的な特徴量、fundamental frequency、音素の遅延量をとるため、専門家による特徴量抽出やパラメータチューニングを必要した。
また、Tacotron[^2]は文字のシーケンスから振幅スペクトグラムを生成するモデルで、伝統的な言語学的、音響学的な特徴抽出をニューラルネットワークで代替した画期的なものだった。しかしながら、音声波形の生成には位相の推定にGriffin-Limアルゴリズムを使用し、後続に短時間フーリエ逆変換を用いている。これはWaveNetのようなアプローチと比較してアーティファクト（=本来出力したい音声とは関係のない情報）を含んでいたり、音質的に劣っている。

本研究ではこれらの既存研究を統合する。すなわち、Tacotron形式のモデルで振幅スペクトグラムを生成し、改良したWaveNetボコーダによって音声生成するアプローチをとる。

[^1]: [WaveNet: A Generative Model for Raw Audio](https://arxiv.org/abs/1609.03499)
[^2]: [Tacotron: Towards End-to-End Speech Synthesis](https://arxiv.org/abs/1703.10135)

# 評価方法

モデルの訓練および評価にはUS English datasetを用いた。このデータセットは1人のプロの女性話者による24.6時間のスピーチからなる。

test setから100サンプルをランダムに抽出し、Amazon Mechanical Turkと同様の人力レーティングサービスを利用して評価した。1サンプルあたり最低8人が1から5まで0.5刻みのレートで評価し、Mean opinion score(MOS)[^3]を算出した。

[^3]: https://en.wikipedia.org/wiki/Mean_opinion_score

# 所感

* ~~この記事執筆時点(2022/08)でいまだにRNNベースの手法がSOTAとなっている。Transformerで実装すると性能改善が期待できるだろうか？~~ TransformerベースのTTS(Text-To-Speech synthesis)モデルとして、2019年にNaihan LiらによってTransormer TTS[^5]が提案されている。このモデルはTacotron2におけるエンコーダ、デコーダをTransformerで設計し直したアーキテクチャで、論文によるとTacotron2と同等の評価性能で4.25倍の学習時間の短縮を実現している。
* 評価指標が人力なのは研究コストが高い。画像の生成モデルのように機械的に判定できる指標(PPLなど)があれば良いのだが。

[^5]: [Neural Speech Synthesis with Transformer Network](https://arxiv.org/abs/1809.08895)
