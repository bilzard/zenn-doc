---
title: "論文メモ: Conditional PixelCNN - PixelCNNベースの条件付き画像生成モデル"
emoji: "🏜"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["論文メモ", "自己回帰モデル", "生成モデル"]
published: true
---

# 論文

[Conditional Image Generation with PixelCNN Decoders](https://arxiv.org/abs/1606.05328)

# 表記

* LL: log likelihood

# 概要

PixelCNNをベースにした条件付き生成モデルを提案する。モデルに与えるコンテクストは任意のラベルやタグ、埋め込みベクトルを指定できる。例えばImageNetのクラスラベルをコンテクストに与えた場合は動物、物体、風景、構造物などのリアルかつ多様な画像を生成する。また、未知の特定の人物の埋め込みベクトルを与えた場合はその人物の様々な表情、ポーズ、照明条件の画像を生成する。また、提案モデルをオートエンコーダのデコーダとして用いた場合、高精細かつ多様な画像を生成する。さらに、提案手法はPixelCNNのLLを改善し、PixelRNNと同等のLLのモデルをPixelRNNの半分以下の時間で学習することに成功した。

# 研究分野における位置付け

* PixelRNN: bi-directional LSTMを用いた自己回帰の生成モデル。並列化できないため学習速度が遅い
* PixelCNN: masked convolutionにより学習の並列化を実現。学習スピードは速いが、LLはPixelRNNに劣る
* Gated PixelCNN (提案手法): 垂直方向と水平方向の2つのCNNを協調して学習することでPixelCNNの"blind spot"の問題を解消。PixelRNNと同程度以上のLLのモデルを半分以下の時間で学習することに成功
* Conditional PixelCNN (提案手法): Gated PixelCNNにコンテクストの情報を与えられるようにした条件付き生成モデル

# 何がすごい？

1. 任意のコンテクストを与えて画像生成を行うモデルを開発した
2. 提案手法はVAEのデコーダとして用いることも可能。この場合、通常のVAEよりも高精細かつ多様な画像を生成する
3. PixelCNNの「盲点」の問題を解消し、PixelRNNと同程度のLL(log likelihood)を半分以下の学習時間で実現

# 提案手法について

まず、基本となるアーキテクチャについて説明する。その後、条件付きで画像を生成する方法について説明し、最後にデコーダとしての応用について述べる。

## Gated Convolution Layer

畳み込みレイヤの代わりに空間的なLSTMレイヤーを採用するPixelRNNは、PixelCNNより優れた性能であることが知られる。この原因の一つとして、再帰接続によって順番的に前にある全ての近傍のピクセルの情報に参照できることが挙げられる。一方、PicelCNNが参照できるピクセルの受容野は畳み込み層が深くなるとともに広がる。この欠点はCNNの層を十分深くすることで回避できる。
PixelRNNのもう一つの潜在的な利点として、乗法ユニット（＝LSTMのゲート）を持つことが挙げられる。このユニットによってより複雑な相互作用を表現できている可能性がある。提案手法では、ゲートの仕組みを導入するために、以下のようなゲートつきの活性層を提案する。

$$y=\tanh {(W_{k, f} * x)} \odot \sigma(W_{k, g}* x) \tag{1}$$

$\sigma$はシグモイド関数で、$\odot$は要素ごとの和、$*$は要素ごとの積を表す。シグモイド関数はゲート（＝特定の情報を通すか通さないかを選択できるユニット）として働く。既存研究でもゲートつきのニューラルネットワークがそれ以前のモデルよりもパフォーマンスがよくなることが報告されている。

## 受容野の「盲点」

PixelCNNの受容野を図1（右上）に示す。PixelCNNは層を深くしても右側に参照されないピクセル（=*盲点*）がある。
これを克服するために、提案手法は*垂直方向*と*水平方向*の2つのCNNに分割する。*垂直方向*のCNNは「対象のピクセルよりも上にある全ての行」を参照するのに対し、*垂直方向*のCNNは「対象ピクセルのある行で、対象ピクセルよりも左側にある全てのピクセル」を参照する。最終的にこれら2つのCNNの処理結果を組み合わせることで、右側の*盲点*をなくすことができ、PixelCNNよりも多くの情報を参照することができる。
なお、*水平方向*のCNNは1つ前の層の自身の出力に加え、1つ前の層の*垂直方向*のCNNの処理結果も入力として受け取る。逆の接続（つまり*垂直方向*から*水平方向*）については順番的に「未来」にある（＝自己回帰でない）ピクセルも参照することになるので接続していないことに注意。また、*水平方向*のCNNは残差接続を持つが、*垂直方向*のCNNは持たない[^1]。最終的な提案手法のアーキテクチャを図2に示す。

[^1]: 論文では「*水平方向*のCNNに残差接続を加えても性能が改善しなかったため」としている。

![](https://storage.googleapis.com/zenn-user-upload/830ec9c478e8-20220806.png)
**図1: PixelCNNと提案手法の受容野の比較: 左) PixelCNNにおける畳み込み演算の可視化, 中央) PixelCNNのフィルタマスク, 右上) PixelCNNの受容野の可視化, 右下) 提案手法の受容野の可視化。PixelCNNは層を深くしても右側に参照されないピクセル（「盲点」）があるのに対し、提案手法はこれがなく、より多くのピクセルの情報を利用できる。**

![](https://storage.googleapis.com/zenn-user-upload/0468ca6c25a6-20220806.png)
**図2: Gated PixelCNNの1層のアーキテクチャ。**

## 条件付き画像生成

論文では条件付きの画像生成を以下のように定義する。

$$p(x|h)=\prod_{i=1}^{n^2} p(x_i| x_{1:i-1}, h) \tag{2}$$

$x$は入力画像で添字はラスター操作した時のピクセル位置を表す。また、$h$はコンテクストを表現したベクトルである。直感的には「全てのピクセルがコンテクストに依存して決定される」ということを表す。この式を元に、活性関数を以下のように定義し直す[^2]。

$$y=\tanh(W_{k, f} * x + V^T_{k, f}h) \odot \sigma(W_{k, g} * x + V^T_{k, g}h) \tag{3}$$

上記はコンテクスト$h$が画像のピクセル位置に依存しない場合を想定しているが、依存する場合、すなわち画像の水平方向と垂直方向に同じサイズを持つコンテクストの空間表現$s=m(h)$が与えられている場合は以下の式で計算する。

$$y=\tanh(W_{k, f} * x + V^T_{k, f} * s) \odot \sigma(W_{k, g} * x + V^T_{k, g} * s) \tag{4}$$

式(4)における$V^T_{k, \bullet}*s$は1x1サイズの畳み込みを表す[^3]。

[^2]: コンテクスト$h$についてもゲートの重みを学習していることに注意。すなわち、$V^T_{k, f}, V^T_{k, g}$はそれぞれ異なる重みである。
[^3]: すなわち、コンテクストの空間表現に空間方向の特徴抽出を行わないことを表す。この理由については論文では触れられていない。私の推測では1)モデル全体のパラメータ数をコンパクトに保つため、あるいは、2) 一般的にコンテクストよりも特徴マップに多くの情報が含まれているためパラメータ数を相応に配分した、のいずれか（または両方）と考えている。

## オートエンコーダへの応用

提案モデルは、オートエンコーダのデコーダとしても利用できる。この場合、コンテクスト$h$としてエンコーダの出力（＝画像の埋め込みベクトル）を指定する。
この場合、図3に示すようにデコーダは元の画像を忠実に再現するというよりは、元の画像のバリエーションを生成する。また、VAEがぼやけた画像を出力するのに対し、Conditional PixelCNNをデコーダとして用いた場合は高精細な画像を出力している。

![](https://storage.googleapis.com/zenn-user-upload/6c11d69d86b6-20220806.png)
**図3: 左) 元画像, 中央) VAEのエンコーダの出力, 右) エンコーダにPixelCNNを用いた場合の再構成画像**

# 所感

* WaveNetやその後継モデル(WaveGlow, WaveFlow)では条件付き生成の仕組みに本論文の手法を採用している
* Gated activationの設計意図が理解できた
* 他の論文（WaveGlow, WaveFlowなど）では自己回帰に特に拘らずに未来のピクセルも参照しているが、本論文では（おそらくPixelCNN, PicelRNNも）注意深く参照しないようにしている。自己回帰を忠実に守ることのメリットには何があるのだろうか？
