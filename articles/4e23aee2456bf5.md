---
title: "[論文要約] Transductive CNAPS + FETI: ラベルなしデータを利用したFew-Shot画像分類タスクの改善"
emoji: "💡"
type: "tech"
topics:
  - "fewshotlearning"
  - "論文要約"
published: true
published_at: "2022-03-08 14:50"
---

# 論文

[Enhancing Few-Shot Image Classification with Unlabelled Examples](https://arxiv.org/abs/2006.12245v6)

# 概要

本提案手法ではFew-Shot画像分類タスクにおいて、CNAPS[^1]という特徴ベクトルベースの手法を拡張し、ラベルなしデータを扱えるようにした。

[^1]: [Improved Few-Shot Visual Classification](https://arxiv.org/abs/1912.03432)

# Few-Shot Learning

問題設定は[^2]と同じ。

[^2]: https://zenn.dev/bilzard/articles/5134f0d3b52b70

# 提案手法の特徴

1. CNAPSを拡張し、ラベルなしデータ(query set[^4])を扱えるようにした
2. Maharanobis距離ベースのsoft k-meansクラスタリングアルゴリズムを使ってクラス中心と共分散行列をiterativeに推定

[^3]: support set: テストラベルのうち、ラベルが付与されたもの
[^4]: query set: テストラベルのうち、ラベルが付与されていないもの

# 提案モデルのアーキテクチャ

アーキテクチャを図示すると図1のようになる。
CNAPSにラベルなしデータを使ってクラスタのパラメータ推定をアップデートするモジュールが追加されている。

![](https://storage.googleapis.com/zenn-user-upload/2ebc806e119d-20220308.png)
*図1: 提案モデルのアーキテクチャ*

# Simple CNAPS

1. ラベル付きデータ(support set[^3])のみを使用
2. inductive[^2]な手法
3. あるラベルなしサンプル[^4]に対して特徴ベクトルが与えられたとき、ラベルありデータ[^3]の分布に基づいて推定したクラスタ中心および共分散行列を使って、ラベルなしサンプルが各クラスに所属する確率を計算する

# Transductive CNAPS

1. 訓練セットを使って事前学習した特徴抽出ネットワークを使ってラベルなしデータの特徴ベクトルを抽出。通常のCNAPSを使って各クラスに所属する確率を求める。
2. 1で計算した確率をソフトラベルとして使用し、ソフトラベルに拡張したCNAPSを使ってクラスタ中心と共分散行列をアップデートする
3. ラベルなしデータが所属するクラスタが収束するまで、あるいは、パラメータとして与えた最大イテレーション回数に到達するまで2の処理を繰り返す

# Bregman Soft Clustering/GMMとの関連性

本手法で利用しているクラスタリングアルゴリズムは、Bregman clustering algorithm[^5]及びGMMと類似している。Bregman clusteringではクラスタ中心のみアップデートするのに対し、提案手法ではクラスタ中心とクラスタ間の共分散行列を共にアップデートする。また、GMMではラベルなしデータをクラスタに割り当てる確率の計算式が提案手法と異なる。

[^5]: [Clustering with Bregman Divergences](https://www.jmlr.org/papers/v6/banerjee05b.html)

# 実験結果

Meta-Dataset, MNIST, CIFAR10/100からなる混合データセットに対してin-domain及びout-of-domainの精度を評価した。

なお、それぞれの実験条件は以下である。
* in-domain: Meta-Datasetの最初の8つのデータセットを使って学習及び評価
* out-of-domain: Meta-Datasetの最初の8つのデータセットを使って学習し、残りの2つ及びMINIST, CIFAR10, CIFAR100の5つのデータセットで評価

この結果、in-domainでは8つ中2つでSOTAを達成し、out-of-domainでは5つ中4つでSOTAを達成した。つまり、提案手法はドメインシフトに対して既存の手法よりもロバストであることが示唆された。

また、tired-ImageNetでは既存のSOTAとタイの精度となり、また、mini-ImageNetではSOTAを下回った。著者らはこの結果を「mini-ImageNetはデータ数(38,400)がとtired-ImageNetのデータ数(448,695)に比べて十分でないため、特徴抽出の精度が十分でないため」と仮説を立てた。
追加の実験として、著者らはImageNetのより大きなサブセットで事前学習した特徴抽出ネットワークを使って学習した提案モデルの精度を評価した。この結果、SOTAを大きく上回る精度を達成した。このことから、特徴抽出ネットワークの精度が本提案手法の精度に大きく依存することが示唆される。

# 所感

* アブレーションの結果から、ラベル付きサンプルの数が10を超えると本手法はSimple CNAPSに比べてsub-optimalであることが示されている。従ってサンプル数が中途半端に多い場合は本手法は逆効果になる可能性がある。
* モデルの精度が特徴抽出ネットワークの精度に大きく依存することに注意。訓練データのサンプル数が不十分だと効果が十分発揮できない可能性がある。
* クラスタのパラメータ推定において、イテレーション数の上限が大きい場合は精度が劣化した。著者らは「過剰適合している可能性がある」としているが、ハイパーパラメータの設定にやや敏感な印象をもった。