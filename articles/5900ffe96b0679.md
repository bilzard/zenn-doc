---
title: "論文解説: WaveGlow - 会話生成におけるFlowベースの生成モデル"
emoji: "👻"
type: "idea"
topics:
  - "音声"
  - "論文解説"
  - "会話生成"
  - "生成モデル"
published: true
published_at: "2022-08-04 12:21"
---

# 論文

[WaveGlow: A Flow-based Generative Network for Speech Synthesis](https://arxiv.org/abs/1811.00002v1)

# 概要

melスペクトグラムから高品質な音声波形を生成するFlowベースの生成モデルを提案する。

# 研究分野における論文の位置付け

典型的なtest-to-speech合成は2ステップで行われる。最初のステップではテキストを時系列に配置された特徴量、すなわちMelスペクトログラムやF0周波数などの言語学的特徴量を生成する。二段階目のモデルはこれらの時系列に配置された特徴から音声サンプルを生成する。本論文では後者のモデルを扱う。

# 既存研究との違い

既存手法のGlow[^1]とWaveNet[^2]の知見を組み合わせ、高速かつ高品質な会話生成モデルを実現した。
WaveNetは高品質な会話生成が可能だが、自己回帰モデルベースの手法のため並列化が難しく、処理速度に課題がある。そこで、Glow同様のFlowベースのアーキテクチャを採用し、自己回帰不要でWaveNetと同等の品質を保ちつつ高速化を実現した。

[^1]: https://arxiv.org/abs/1807.03039 。[過去の論文解説記事](https://zenn.dev/bilzard/articles/554e37c7f3bcd2)も参照のこと。
[^2]: https://arxiv.org/abs/1609.03499

# 評価方法

提案手法のpytorch実装は、NVIDIA V100 GPU x1で507kHzのサンプルレートでの会話生成を実現した（WaveNetは0.11kHz）。また、Mean Opinion Scoreによる評価においてWaveNetと同等の品質を実現した。

**表1: 既存手法と提案手法のMOSの比較**
![](https://storage.googleapis.com/zenn-user-upload/b781183f7402-20220804.png)

# 提案手法の特徴と解説

## Melスペクトグラムを入力とする条件付き生成モデル

mel-spectrogramを条件として与えたFlowベースの生成モデルである（図1）。
基本的にはGlowと同様の構造だが、Affine coupling layerのアフィン変換パラメータの生成において、入力テンソルに加えてmelスペクトグラムの振幅を与えている（図2）。

**図1: WaveGlowのアーキテクチャ**
![](https://storage.googleapis.com/zenn-user-upload/17acc9610e0d-20220804.png)

**図2: Affine coupling layerの定義**
![](https://storage.googleapis.com/zenn-user-upload/d5b78647c754-20220804.png)

## Early outputs

全てのチャネルを全てのレイヤを通過させるのでなく、4つのcoupling layerごとに2つのチャネルを出力する。最後に各中間レイヤの出力をconcatすることで最終的な出力を得る。このような仕組みは、ネットワークの浅いレイヤに勾配を伝搬させやすくするので、Skip connectionと同等の効果が期待できる。

## 生成時の工夫

Flowベースの生成手法は生成時は潜在空間からある確率分布（通常は球面ガウス分布$\mathcal{N}(z; 0, I)$）でサンプルした$z$を入力として、モデルの逆変換を計算することで生成データ$x$を得る。

Glowや他の尤度ベースの生成手法で提案されているように、サンプルする潜在空間のガウス分布の分散を訓練時よりも小さくすることで若干精度の良い出力を得ることができる[^3]。提案手法では訓練時は$\sigma=\sqrt{0.5}$に対し、生成時は$\sigma=0.6$を用いた。

[^3]: おそらく中心から大きく外れたサンプルを得ることを防止するもの。GANにおける確率分布の両サイドをClippingするトリックと同じと思われる。

## Squeeze処理について

注目するtime frameを短いフレームごとのチャンクに分割し、それらをまとめて並列処理するためのテンソルの変形処理のことを意味しているようである。モデルが学習する、時系列データの時間的な依存性は、このチャンク内に限られる。

公式実装[^4]によると、time frameを8 frameごとのチャンクに分割し、$T/8$個のグループに分割する。Affine Coupling layerにおけるNNの入力として$(N, F \times 8, T / 8)$のサイズのテンソルを入力している。
なお、サンプリングレートが22.05kHz, hop size=256であるから、1フレームあたりの解像度は11.6msで、8フレームでは92.8msに相当する。つまり、提案手法はこの時間領域を対象にMelスペクトグラムと音声波形の関係を学習している[^5]。

![](https://storage.googleapis.com/zenn-user-upload/cf3ae944035e-20220804.png)

[^4]: https://github.com/NVIDIA/waveglow
[^5]: 逆に言えば、92.8msを超える時系列データの依存性は考慮しないことを意味する。hop-sizeなどの信号処理のパラメータは、対象データのドメインに応じて適切に設定すべきである。