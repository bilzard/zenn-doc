---
title: "論文要約: AST - Vision Transformerの音声タスクへの適用"
emoji: "🦋"
type: "idea"
topics:
  - "論文要約"
  - "音声"
  - "transformer"
  - "機械学習"
published: true
published_at: "2022-03-03 00:02"
---

# 論文

[AST: Audio Spectrogram Transformer](https://arxiv.org/abs/2104.01778v3)

# 概要

CNNの上にattention moduleを付け足したハイブリッドなモデルが既存であるのに対し、本論文ではConvolutionなしのpureなtransformerのモデルを提案する。

# 提案手法の特徴

1. 学習時間の短縮のため ViT[^1], DeiT[^2]にてImage Netで学習した重みを流用
2. Positional Embeddingを内挿することで可変長の入力に対応。かつ既存の重みも流用

可変長入力に対応したことはモデルの汎用性という意味では特筆すべきである。

# 提案手法のパフォーマンス

AudioSetにおける音声タギングのタスクにてSOTAを達成(mAP=**0.485**)。
SOTAといってもmAPに寄与したのはほとんどweight averagingとensembleであることに注意。single modelのmAPは0.448。
また、mel-spectrogramの量子化数が128であるが、これはPANNs[^3]において同じ量子化数で0.442を達成しているため、シングルモデルで見ると実はdrasticな改善ではない。

[^1]: [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)
[^2]: [Training data-efficient image transformers & distillation through attention](https://arxiv.org/abs/2012.12877v2)
[^3]: [PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition](https://arxiv.org/abs/1912.10211)
