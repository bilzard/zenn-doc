---
title: "論文要約: Partial FC - softmaxベースの顔認識モデルの効率的でロバストな学習手法"
emoji: "🦔"
type: "tech"
topics:
  - "顔認識"
  - "論文要約"
published: true
published_at: "2022-05-29 19:44"
---

https://arxiv.org/abs/2203.15565

## はじめに

顔認識におけるsoftmaxベースの手法において、バッチ内の負例のサンプルの一部のみを使って重みを更新することで、1) 処理速度の高速化、2) メモリ消費の効率化、3) 精度の改善を全て達成した手法。

## 既存の手法の問題点

まず、顔認識における問題点として以下がある：
1) 異なるクラスによく似た画像が一定数含まれる（inter-class conflict）
2) 各クラスのサンプル数の不均衡
3) クラス数に比例してFC層の計算コストとメモリ消費が肥大化する

### 1) inter-class conflict

同じ人物が異なるクラスに一定数現れることにより、inter-class discrepancyが悪化するというもの。
データセットの誤ラベルに起因する。

### 2) クラス数の不均衡

一般的に、どのデータセットにも人物クラスごとにサンプル数に不均衡がある。特に、long-tailに属するクラスは、後述するように重み更新において負例の影響を過大に受けることから、収束した重みにおいて真のクラス中心からずれる問題がある。

![](https://storage.googleapis.com/zenn-user-upload/d42bcf8ccc40-20220529.png)

### 3) FC層のメモリ消費と計算コストの肥大化

softmaxベースの手法ではFC層の重みはクラス数に比例して大きくなる。対象クラスが1M以上になると、GPUメモリ消費、及び計算コストにおいてバックエンドのそれと比較して支配的になる。

![](https://storage.googleapis.com/zenn-user-upload/8b672c60d853-20220529.png)

## 問題の原因

softmaxベースの手法における重みの更新式は(3)式で表される。
- pi_plus, pi_minus: 正例および負例の予測確率
- xi_plus, xi_minus: 正例および負例の特徴ベクトル
- B_plus, B_minus: バッチ内における正例および負例のサンプルの集合

![](https://storage.googleapis.com/zenn-user-upload/7ede85916dc4-20220529.png)

inter-class conflictなサンプルでは、本来正例であるはずのサンプルが負例として扱われるため、(3)式におけるxi_minusが実際と異なる値となる。従ってこのようなサンプルが多いとクラス中心の重み収束値が真の値から離れてしまう。

第二に、ロングテールではサンプル数が数個というケースがあるが、このようなクラスは非常に高い確率でバッチ内に正例がない。従って、このようなクラスでは(3)式の更新は高い確率で行われない。一方で、別のクラスの重み更新において負例のペナルティが適用され、他クラスの中心から離される。従ってロングテールのクラスの収束後の重みは、真のクラス中心から離れやすい。

第三に、FC層のメモリ消費と計算コストはクラス数に比例して増大し、これはGPUを並列化しても解消されない。

## 提案手法

問題点1, 2の本質的原因は、重み更新における負例の更新頻度に不均衡があることである。従って、本論文ではバッチ内の負例を全て使うのではなく、部分的にサンプルすることで、softmax損失計算における負例の影響を小さくする手法を提案する（4式）。

![](https://storage.googleapis.com/zenn-user-upload/702fa714e8b2-20220529.png)

重み更新で利用する負例の数を小さくすることは、問題1, 2における重み更新の負例の更新頻度の不均衡を緩和する。同時に、GPU上に確保するメモリ量と計算量をサンプルレートに比例して削減できる。